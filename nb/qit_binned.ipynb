{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import qp\n",
    "import qit\n",
    "from scipy.optimize import minimize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# true distribution of redshifts\n",
    "Z_TRUE_MIN, Z_TRUE_MAX = 0., 2.\n",
    "LOC_TRUE = 0.60\n",
    "SCALE_TRUE = 0.30\n",
    "N_TRUE_BINS = 10\n",
    "\n",
    "true_bins = np.linspace(Z_TRUE_MIN, Z_TRUE_MAX, N_TRUE_BINS+1)\n",
    "\n",
    "true_dist_norm = qp.Ensemble(qp.stats.norm, data=dict(loc=[[LOC_TRUE]], scale=[[SCALE_TRUE]]))\n",
    "true_dist = qp.convert(true_dist_norm, 'hist', bins=true_bins)\n",
    "ax_true = true_dist.plot(xlim=(Z_TRUE_MIN, Z_TRUE_MAX), label=r\"unnorm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit prior\n",
    "\n",
    "Now we make the implicit prior.  In our case it is similiar to the true distribution, but slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOC_PRIOR = 0.65\n",
    "SCALE_PRIOR = 0.35\n",
    "implicit_prior_norm = qp.Ensemble(qp.stats.norm, data=dict(loc=[[LOC_PRIOR]], scale=[[SCALE_PRIOR]]))\n",
    "implicit_prior = qp.convert(implicit_prior_norm, 'hist', bins=true_bins)\n",
    "ax_prior = implicit_prior.plot(xlim=(Z_TRUE_MIN, Z_TRUE_MAX), label=r\"unnorm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator\n",
    "\n",
    "Now we try and model the behavior of a simple estimator.\n",
    "Our simple estimator has a likelihood $p(d | z)$ to return an esimate $d$ for a true value $z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This represents the \"estimator\" code, we define 10 bins (in true redshift)\n",
    "# and in each bin the likelihood p(z_obs) is a Gaussian centered on the bin center\n",
    "\n",
    "N_EST_BINS = N_TRUE_BINS\n",
    "\n",
    "z_bins = np.linspace(Z_TRUE_MIN, Z_TRUE_MAX, N_EST_BINS+1)\n",
    "z_centers = qp.utils.edge_to_center(z_bins)\n",
    "z_widths = 0.2 * np.ones(N_EST_BINS)\n",
    "likelihood = qp.Ensemble(qp.stats.norm, data=dict(loc=np.expand_dims(z_centers, -1), scale=np.expand_dims(z_widths, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# These are the points at which we evaluate the PDFs\n",
    "N_OBS_BINS = 300\n",
    "Z_OBS_MIN, Z_OBS_MAX = -0.5, 2.5\n",
    "grid_edge = np.linspace(Z_OBS_MIN, Z_OBS_MAX, N_OBS_BINS+1)\n",
    "grid_cent = qp.utils.edge_to_center(grid_edge)\n",
    "p_grid = likelihood.pdf(grid_cent)\n",
    "\n",
    "plot_kwds = dict(xlabel=r'$z_{\\rm true}$',\n",
    "                 ylabel=r'$d$',\n",
    "                 extent=(Z_TRUE_MIN, Z_TRUE_MAX, Z_OBS_MIN, Z_OBS_MAX),\n",
    "                 origin='lower')\n",
    "\n",
    "pl_like = qit.plotting.plot_2d_like(p_grid.T, **plot_kwds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_estim = qit.Estimator([z_bins], likelihood)\n",
    "flat_post = like_estim.flat_posterior(grid_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior distributions\n",
    "\n",
    "Ok, now we are going to extract the posterior distributions $p(z|d)$, $p(z|d,\\phi^{\\dagger})$ and $p(z|d,\\phi^{*})$.  In our case these correspond to the posteriors assuming a flat prior, assuming the true distribution as the prior and assuming the implicit prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's flip around the likelihood\n",
    "z_grid = np.linspace(Z_TRUE_MIN, Z_TRUE_MAX, 101)\n",
    "#z_grid = z_centers\n",
    "#flat_post = qp.Ensemble(qp.stats.hist, data=dict(bins=z_bins, pdfs=p_grid.T))\n",
    "\n",
    "post_grid = flat_post.get_posterior_grid(z_grid)\n",
    "est_grid = flat_post.get_posterior_grid(z_grid, implicit_prior)\n",
    "true_grid = flat_post.get_posterior_grid(z_grid, true_dist)\n",
    "\n",
    "#post_grid = qp.like_funcs.get_posterior_grid(flat_post, z_grid)\n",
    "#est_grid = qp.like_funcs.get_posterior_grid(flat_post, z_grid, implicit_prior)\n",
    "#true_grid = qp.like_funcs.get_posterior_grid(flat_post, z_grid, true_dist)\n",
    "\n",
    "pl_post = qit.plotting.plot_2d_like(post_grid, **plot_kwds)\n",
    "pl_est = qit.plotting.plot_2d_like(est_grid, **plot_kwds)\n",
    "pl_true = qit.plotting.plot_2d_like(true_grid, **plot_kwds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's sample points in true z\n",
    "N_SAMPLES = 10000\n",
    "N_HIST_BINS = 50\n",
    "z_true_sample = np.squeeze(true_dist.rvs(size=N_SAMPLES))\n",
    "fig_sample, ax_sample = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                                     xlabel=r\"$z_{\\rm true}$\",\n",
    "                                                     ylabel=\"Counts / %0.2f\" % ((Z_TRUE_MAX-Z_TRUE_MIN)/N_HIST_BINS))\n",
    "hist = ax_sample.hist(z_true_sample, bins=np.linspace(Z_TRUE_MIN, Z_TRUE_MAX, N_HIST_BINS+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample points from the true distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a sample of points in the measured distribution\n",
    "\n",
    "We do this by sampling a $d$ value from the correct bin for each sampled value in $z_{\\rm true}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a sample of points in measured z.\n",
    "N_OBS_HIST_BINS = 75\n",
    "#whichbin = np.searchsorted(z_bins, z_true_sample)-1\n",
    "#mask = (z_true_sample > 0) * (z_true_sample <= 2.0)\n",
    "#mask *= (whichbin < z_centers.size)\n",
    "#whichbin = whichbin[mask]\n",
    "\n",
    "#sampler = qp.Ensemble(qp.stats.norm, data=dict(loc=np.expand_dims(z_centers[whichbin], -1),\n",
    "#                                               scale=np.expand_dims(z_widths[whichbin], -1)))\n",
    "sampler = like_estim.get_sampler(z_true_sample)\n",
    "mask = (z_true_sample > 0) * (z_true_sample <= 2.0)\n",
    "z_meas_sample = np.squeeze(sampler.rvs(1))\n",
    "\n",
    "fig_hmeas, ax_hmeas = qp.plotting.make_figure_axes(xlim=(Z_OBS_MIN, Z_OBS_MAX),\n",
    "                                                   xlabel=r\"$z_{\\rm true}$\",\n",
    "                                                   ylabel=\"Counts / %0.2f\" % ((Z_OBS_MAX-Z_OBS_MIN)/N_OBS_HIST_BINS))\n",
    "\n",
    "hist = ax_hmeas.hist(z_meas_sample, bins=np.linspace(Z_OBS_MIN, Z_OBS_MAX, N_OBS_HIST_BINS+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overplot the scatter plot on the 2-d likelihood plot\n",
    "pl_true = qit.plotting.plot_2d_like(p_grid.T, **plot_kwds)\n",
    "ax_like2 = pl_true\n",
    "sc = ax_like2.scatter(z_true_sample[mask], z_meas_sample, s=1, color='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile plot\n",
    "\n",
    "The previous plot is a bit messy, lets plot the mean and std in slices of x.  (This is a \"profile\" plot in particle physics jargon.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PROF_BINS = 10\n",
    "pl_true2 = qit.plotting.plot_2d_like(p_grid.T, **plot_kwds)\n",
    "ax_prof = pl_true2\n",
    "x_prof = np.linspace(Z_TRUE_MIN, Z_TRUE_MAX, N_PROF_BINS+1)\n",
    "x_prof_cent = qp.utils.edge_to_center(x_prof)\n",
    "prof_vals, prof_errs = qp.utils.profile(z_true_sample[mask], z_meas_sample, x_prof)\n",
    "sc = ax_prof.errorbar(x_prof_cent, prof_vals, yerr=prof_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posteriors for the measured values\n",
    "\n",
    "Now we get $p(z|d_{j})$, $p(z | d_{j}, \\phi^{\\dagger})$ and $p(z | d_{j}, \\phi^{*})$ for the samples we simulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we get the posteriors for all the measured values\n",
    "z_meas_bin = np.searchsorted(grid_edge, z_meas_sample)\n",
    "z_meas_mask = (z_meas_bin >= 0) * (z_meas_bin < grid_cent.size)\n",
    "z_meas_bin = z_meas_bin[z_meas_mask]\n",
    "\n",
    "post_ens = like_estim.make_posterior_ensemble(z_grid, z_true_sample)\n",
    "est_ens = like_estim.make_posterior_ensemble(z_grid, z_true_sample, implicit_prior)\n",
    "true_ens = like_estim.make_posterior_ensemble(z_grid, z_true_sample, true_dist)\n",
    "\n",
    "def make_dict(ens, z_grid):\n",
    "    vals = ens.pdf(z_grid)\n",
    "    return dict(ens=ens, vals=vals, stack=vals.mean(axis=0))\n",
    "\n",
    "post_dict_o = qit.like_funcs.make_ensemble_for_posterior_interp(post_grid, z_grid, z_meas_bin)\n",
    "est_dict_o = qit.like_funcs.make_ensemble_for_posterior_interp(est_grid, z_grid, z_meas_bin)\n",
    "true_dict_o = qit.like_funcs.make_ensemble_for_posterior_interp(true_grid, z_grid, z_meas_bin)\n",
    "post_dict_i = make_dict(post_ens, z_grid)\n",
    "est_dict_i = make_dict(est_ens, z_grid)\n",
    "true_dict_i = make_dict(true_ens, z_grid)\n",
    "\n",
    "post_dict = post_dict_i\n",
    "est_dict = est_dict_i\n",
    "true_dict = true_dict_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_sample = np.argmax(z_meas_sample[0:10])\n",
    "print(which_sample, z_meas_sample[which_sample])\n",
    "fig_x, ax_x = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                           xlabel=r\"$z_{\\rm true}$\",\n",
    "                                           ylabel=r\"$p(z)$\")\n",
    "\n",
    "ax_x.plot(z_grid, post_dict['vals'][which_sample], label='implicit=flat')\n",
    "ax_x.plot(z_grid, est_dict['vals'][which_sample], label='implicit=estimated')\n",
    "ax_x.plot(z_grid, true_dict['vals'][which_sample], label='implict=true')\n",
    "ax_x.plot(z_grid, np.squeeze(implicit_prior.pdf(z_grid)), label='implicit prior')\n",
    "ax_x.plot(z_grid, np.squeeze(true_dist.pdf(z_grid)), label='true')\n",
    "leg = fig_x.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_sample = np.argmax(z_meas_sample[0:10])\n",
    "print(which_sample, z_meas_sample[which_sample])\n",
    "fig_x, ax_x = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                           xlabel=r\"$z_{\\rm true}$\",\n",
    "                                           ylabel=r\"$p(z)$\")\n",
    "\n",
    "ax_x.plot(z_grid, post_dict_o['vals'][which_sample], label='implicit=flat')\n",
    "ax_x.plot(z_grid, est_dict_o['vals'][which_sample], label='implicit=estimated')\n",
    "ax_x.plot(z_grid, true_dict_o['vals'][which_sample], label='implict=true')\n",
    "ax_x.plot(z_grid, np.squeeze(implicit_prior.pdf(z_grid)), label='implicit prior')\n",
    "ax_x.plot(z_grid, np.squeeze(true_dist.pdf(z_grid)), label='true')\n",
    "leg = fig_x.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the true distribtuion to the naive \"stacking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_stack, ax_stack = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                                   xlabel=r\"$z_{\\rm true}$\",\n",
    "                                                   ylabel=r\"$p(z)$\")\n",
    "ax_stack.hist(z_true_sample[mask], bins=z_bins, density=True, label=r'$z_{\\rm true}$', histtype='step')\n",
    "ax_stack.plot(z_grid, np.squeeze(true_dist.pdf(z_grid)), label=r'$p(z)$')\n",
    "ax_stack.plot(z_grid, post_dict['stack'], label=r'$\\sum_{j} p(z | d_{j})$')\n",
    "ax_stack.plot(z_grid, est_dict['stack'], label=r'$\\sum_{j} p(z | d_{j} \\phi^{*})$')\n",
    "ax_stack.plot(z_grid, true_dict['stack'], label=r'$\\sum_{j} p(z | d_{j} \\phi^{\\dagger})$')\n",
    "leg = fig_stack.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot some posterior distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1, ax_1 = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                                   xlabel=r\"$z_{\\rm true}$\",\n",
    "                                                   ylabel=r\"$p(z)$\")\n",
    "fig_2, ax_2 = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                                   xlabel=r\"$z_{\\rm true}$\",\n",
    "                                                   ylabel=r\"$p(z)$\")\n",
    "\n",
    "post_vals = post_dict['vals']\n",
    "est_vals = est_dict['vals']\n",
    "for i in range(5):\n",
    "    ax_1.plot(z_grid, post_vals[i])\n",
    "    ax_2.plot(z_grid, est_vals[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the likelihood function by evaluating it for a flat distribution and for the true distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FIT_BINS = N_TRUE_BINS\n",
    "model_params = np.ones((1, N_FIT_BINS))\n",
    "model = qp.Ensemble(qp.stats.hist, data=dict(bins=true_bins, pdfs=model_params))\n",
    "\n",
    "N_EVAL_PTS = 201\n",
    "eval_grid = np.linspace(Z_TRUE_MIN, Z_TRUE_MAX, N_EVAL_PTS)\n",
    "model_params = np.log(np.ones(N_FIT_BINS))\n",
    "hist_cents = qp.utils.edge_to_center(z_grid)\n",
    "true_vals = np.histogram(z_true_sample, bins=np.linspace(Z_TRUE_MIN, Z_TRUE_MAX, N_FIT_BINS+1))[0]\n",
    "v_flat = qit.like_funcs.log_hyper_like(model_params, est_dict['ens'], model, implicit_prior, eval_grid)\n",
    "v_true = qit.like_funcs.log_hyper_like(np.log(true_vals), est_dict['ens'], model, implicit_prior, eval_grid)\n",
    "print(v_flat, v_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the objective function for fitting\n",
    "\n",
    "In this case it is just the log_hyper_like with all of the arguments except for the logs of the bin heights, (i.e. the fitting parameters) specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_func = qit.like_funcs.make_log_hyper_obj_func(ensemble=est_dict['ens'],\\\n",
    "                   model=model, implicit_prior=implicit_prior, grid=eval_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_flat = obj_func(model_params)\n",
    "v_true = obj_func(np.log(true_vals))\n",
    "print(v_flat, v_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit for the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(obj_func, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the current value of the objective function\n",
    "obj_func(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the parameters and convert back to counts (The Jacobian happens to be identical to the fitted values)\n",
    "fitted_vals = np.exp(result['x'])\n",
    "fitted_errs = np.sqrt(np.array([result['hess_inv'][i,i] for i in range(N_FIT_BINS)]))\n",
    "norm_factor = 2 / fitted_vals.sum()\n",
    "normed_fit = norm_factor * fitted_vals\n",
    "jac = fitted_vals\n",
    "# Convert to PDF, for plotting\n",
    "normed_errs = norm_factor * jac * fitted_errs\n",
    "model.update_objdata(dict(pdfs=np.expand_dims(normed_fit, 0)))\n",
    "model_vals = np.squeeze(model.pdf(z_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_result, ax_result = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                                     xlabel=r\"$z_{\\rm true}$\",\n",
    "                                                     ylabel=r\"$p(z)$\")\n",
    "ax_result.set_xlim(Z_TRUE_MIN, Z_TRUE_MAX)\n",
    "ax_result.set_ylabel(r'$p(z)$')\n",
    "ax_result.set_xlabel(r'$z_{\\rm true}$')\n",
    "ax_result.plot(z_grid, np.squeeze(true_dist.pdf(z_grid)), label=r'$p(z)$')\n",
    "ax_result.plot(z_grid, post_dict['stack'], label=r'$\\sum_j p(z | d_{j}$)')\n",
    "ax_result.plot(z_grid, est_dict['stack'], label=r'$\\sum_j p(z | d_{j}, \\phi^{*})$')\n",
    "ax_result.plot(z_grid, true_dict['stack'], label=r'$\\sum_j p(z | d_{j}, \\phi^{\\dagger})$')\n",
    "#ax_result.errorbar(hist_cents, normed_fit, yerr=normed_errs, label=\"result\")\n",
    "ax_result.plot(z_grid, model_vals, label='model')\n",
    "leg = fig_result.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting in counts space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LIKE_PTS = 301\n",
    "N_OBS_BINS = 15\n",
    "like_grid = np.linspace(Z_OBS_MIN, Z_OBS_MAX, N_LIKE_PTS)\n",
    "eval_bins = np.searchsorted(z_bins, eval_grid, side='left')\n",
    "eval_mask = (eval_bins >= 0) * (eval_bins < z_bins.size-1)\n",
    "eval_grid = eval_grid[eval_mask]\n",
    "eval_bins = eval_bins[eval_mask]\n",
    "like_eval = likelihood.pdf(like_grid)[eval_bins]\n",
    "obs_cts_grid = np.linspace(Z_OBS_MIN, Z_OBS_MAX, N_OBS_BINS+1)\n",
    "data_cts = np.histogram(z_meas_sample, bins=obs_cts_grid)[0]\n",
    "\n",
    "obj_func_binned = qit.like_funcs.make_binnned_loglike_obj_func(model=model, data_cts=data_cts,\\\n",
    "                          like_eval=like_eval, like_grid=like_grid, model_grid=eval_grid, cts_grid=obs_cts_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = 0.5*data_cts.sum()*np.ones(N_FIT_BINS)\n",
    "model_flat = qit.like_funcs.model_counts(np.log(flat), model, like_eval, like_grid, eval_grid, obs_cts_grid)\n",
    "model_true = qit.like_funcs.model_counts(np.log(true_vals), model, like_eval, like_grid, eval_grid, obs_cts_grid)\n",
    "ll_flat = obj_func_binned(np.log(flat))\n",
    "ll_true = obj_func_binned(np.log(true_vals))\n",
    "print(ll_flat, ll_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(obj_func_binned, np.ones(N_FIT_BINS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cts = qit.like_funcs.model_counts(result['x'], model, like_eval, like_grid, eval_grid, obs_cts_grid)\n",
    "cts_cent = 0.5 * (obs_cts_grid[1:] + obs_cts_grid[:-1])\n",
    "fig_fit, ax_fit = qp.plotting.make_figure_axes(xlim=(Z_OBS_MIN, Z_OBS_MAX),\n",
    "                                               xlabel=r'$z_{\\rm true}$',\n",
    "                                               ylabel=r'$n(z)$')\n",
    "ax_fit.set_yscale('log')\n",
    "ax_fit.set_ylim(1., 1e4)\n",
    "ax_fit.scatter(cts_cent, data_cts, label='data')\n",
    "ax_fit.plot(cts_cent, model_cts, label='fit')\n",
    "leg = fig_fit.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_cts = np.exp(result['x'])\n",
    "true_cents = qp.utils.edge_to_center(true_bins)\n",
    "pdf_true = true_vals * 2 / true_vals.sum()\n",
    "fig_fit2, ax_fit2 = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                                xlabel=r'$z_{\\rm true}$',\n",
    "                                                ylabel=r'n(z)')\n",
    "ax_fit2.plot(z_grid, 0.1*data_cts.sum()*np.squeeze(true_dist.pdf(z_grid)), label=r'$p(z)$')\n",
    "ax_fit2.plot(true_cents, fit_cts, label=\"fit\")\n",
    "ax_fit2.plot(z_grid, 0.1*data_cts.sum()*model_vals, label='model')\n",
    "leg = fig_fit2.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
