{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A `qit` implementation of the CHIPPR algorithm\n",
    "\n",
    "_Eric Charles & Alex Malz_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a real use case of `qit`, to reproduce the results of [CHIPPR](https://arxiv.org/abs/2007.12178)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import qp\n",
    "import qit\n",
    "from scipy.optimize import minimize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True redshift distribution $n^{\\dagger}(z)$\n",
    "\n",
    "First, we make a true distribution.  \n",
    "For this simple example, it is just a Gaussian\n",
    "\n",
    "`true_dist` = $n^{\\dagger}(z) = p(z | \\phi^{\\dagger})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# true distribution of redshifts\n",
    "Z_TRUE_MIN, Z_TRUE_MAX = 0., 2.\n",
    "LOC_TRUE = 0.60\n",
    "SCALE_TRUE = 0.30\n",
    "\n",
    "true_dist = qp.Ensemble(qp.stats.norm, data=dict(loc=LOC_TRUE, scale=SCALE_TRUE))\n",
    "ax_true = true_dist.plot(xlim=(Z_TRUE_MIN, Z_TRUE_MAX), label=r\"unnorm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit prior $n^{*}(z)$\n",
    "\n",
    "Now we make the implicit prior.  \n",
    "In our case it is similiar to the true redshift distribution, but slightly different.\n",
    "\n",
    "implicit_prior = $n^{*}(z) = p(z|\\phi^{*})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOC_PRIOR = 0.65\n",
    "SCALE_PRIOR = 0.35\n",
    "implicit_prior = qp.Ensemble(qp.stats.norm, data=dict(loc=LOC_PRIOR, scale=SCALE_PRIOR))\n",
    "ax_prior = implicit_prior.plot(xlim=(Z_TRUE_MIN, Z_TRUE_MAX), label=r\"unnorm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model of physical likelihoods $p(d | z)$\n",
    "\n",
    "Now we try a simplistic model for the behavior of the space of photometry and redshift $p(z, d)$.\n",
    "A likelihood $p(d | z)$ in this space would correspond to a distribution over possible data $d$ for a true value $z$.\n",
    "$d$ would be multidimensional in real life, one dimension per photometric filter, but we're assuming there's a unique projection of the photometry into a univariate $d$.\n",
    "\n",
    "`likelihood` is $\\mathcal{L}(d | i)$           # Where i is a bin index\n",
    "\n",
    "`like_estim` is $\\mathcal{L}(d | z_{\\rm true})$   # This does the lookup to map z_true -> i\n",
    "\n",
    "**Note: `likelihood` and `like_estim` might be better named `like_binned`/`like_discrete` and `like_continuous`/`like_true` respectively**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This represents the true model of photometry and redshift, we define 50 bins (in true redshift)\n",
    "# and in each bin the likelihood p(z_obs) is a Gaussian centered on the bin center\n",
    "\n",
    "N_EST_BINS = 50\n",
    "\n",
    "z_bins = np.linspace(Z_TRUE_MIN, Z_TRUE_MAX, N_EST_BINS+1)\n",
    "z_centers = qp.utils.edge_to_center(z_bins)\n",
    "z_widths = 0.2 * np.ones(N_EST_BINS)\n",
    "likelihood = qp.Ensemble(qp.stats.norm, data=dict(loc=np.expand_dims(z_centers, -1), scale=np.expand_dims(z_widths, -1)))\n",
    "like_estim = qit.Estimator([z_bins], likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the photometric data points at which we will evaluate posterior PDFs\n",
    "N_OBS_BINS = 300\n",
    "Z_OBS_MIN, Z_OBS_MAX = -0.5, 2.5\n",
    "grid_edge = np.linspace(Z_OBS_MIN, Z_OBS_MAX, N_OBS_BINS+1)\n",
    "grid_cent = qp.utils.edge_to_center(grid_edge)\n",
    "p_grid = likelihood.pdf(grid_cent)\n",
    "\n",
    "plot_kwds = dict(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                 ylim=(Z_OBS_MIN, Z_OBS_MAX), \n",
    "                 xlabel=r'$z_{\\rm true}$',\n",
    "                 ylabel=r'$d$')\n",
    "pl_like = qit.plotting.plot_2d_like(p_grid.T, **plot_kwds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-galaxy posterior distributions\n",
    "\n",
    "Ok, now we are going to extract the posterior distributions \n",
    "\n",
    "true posteriors of the physical model = `post_grid` = $p(z|d)$\n",
    "\n",
    "estimated posteriors for an estimator with implicit prior $\\phi^{*}$ = `est_grid` = $p(z|d,\\phi^{*})$ \n",
    "\n",
    "true posteriors of the galaxy sample = `true_grid` = $p(z|d,\\phi^{\\dagger})$. \n",
    "\n",
    "In our case these correspond to the posteriors assuming a flat prior, assuming the true distribution as the prior and assuming the implicit prior. **I am confused. What does the preceding sentence mean?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_estim = qit.Estimator([z_bins], likelihood)\n",
    "flat_post = like_estim.flat_posterior(grid_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's flip around the likelihood\n",
    "z_grid = np.linspace(Z_TRUE_MIN, Z_TRUE_MAX, 101)\n",
    "\n",
    "post_grid = flat_post.get_posterior_grid(z_grid)\n",
    "est_grid = flat_post.get_posterior_grid(z_grid, implicit_prior)\n",
    "true_grid = flat_post.get_posterior_grid(z_grid, true_dist)\n",
    "\n",
    "pl_post = qit.plotting.plot_2d_like(post_grid, **plot_kwds)\n",
    "pl_est = qit.plotting.plot_2d_like(est_grid, **plot_kwds)\n",
    "pl_true = qit.plotting.plot_2d_like(true_grid, **plot_kwds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: plots above should have axis labels swapped accordingly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample galaxy redshifts from the true redshift distribution $n^{\\dagger}(z)$\n",
    "\n",
    "Here we make a histogram of 10000 true redshifts sampled from $p(z|\\phi^{\\dagger})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now let's sample points in true z\n",
    "N_SAMPLES = 10000\n",
    "N_HIST_BINS = 50\n",
    "z_true_sample = np.squeeze(true_dist.rvs(size=N_SAMPLES))\n",
    "fig_sample, ax_sample = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                                     xlabel=r\"$z_{\\rm true}$\",\n",
    "                                                     ylabel=\"Counts / %0.2f\" % ((Z_TRUE_MAX-Z_TRUE_MIN)/N_HIST_BINS))\n",
    "hist = ax_sample.hist(z_true_sample, bins=np.linspace(Z_TRUE_MIN, Z_TRUE_MAX, N_HIST_BINS+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a sample of photometric \"data\" of the physical model\n",
    "\n",
    "We do this by sampling a $d$ value from the correct bin for each sampled value in $z_{\\rm true}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a sample of points in measured z.\n",
    "N_OBS_HIST_BINS = 75\n",
    "\n",
    "sampler = like_estim.get_sampler(z_true_sample)\n",
    "mask = (z_true_sample > 0) * (z_true_sample <= 2.0)\n",
    "z_meas_sample = np.squeeze(sampler.rvs(1))\n",
    "\n",
    "fig_hmeas, ax_hmeas = qp.plotting.make_figure_axes(xlim=(Z_OBS_MIN, Z_OBS_MAX),\n",
    "                                                   xlabel=r\"$z_{\\rm true}$\",\n",
    "                                                   ylabel=\"Counts / %0.2f\" % ((Z_OBS_MAX-Z_OBS_MIN)/N_OBS_HIST_BINS))\n",
    "\n",
    "hist = ax_hmeas.hist(z_meas_sample, bins=np.linspace(Z_OBS_MIN, Z_OBS_MAX, N_OBS_HIST_BINS+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: x axis above should be $d$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overplot the scatter plot on the 2-d likelihood plot\n",
    "pl_true = qit.plotting.plot_2d_like(p_grid.T, **plot_kwds)\n",
    "ax_like2 = pl_true[1]\n",
    "sc = ax_like2.scatter(z_true_sample[mask], z_meas_sample, s=1, color='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile plot of likelihoods\n",
    "\n",
    "The previous plot is a bit messy, lets plot the mean and std in slices of x.  (This is a \"profile\" plot in particle physics jargon.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PROF_BINS = 20\n",
    "pl_true2 = qit.plotting.plot_2d_like(p_grid.T, **plot_kwds)\n",
    "ax_prof = pl_true2[1]\n",
    "x_prof = np.linspace(Z_TRUE_MIN, Z_TRUE_MAX, N_PROF_BINS+1)\n",
    "x_prof_cent = qp.utils.edge_to_center(x_prof)\n",
    "prof_vals, prof_errs = qp.utils.profile(z_true_sample[mask], z_meas_sample, x_prof)\n",
    "sc = ax_prof.errorbar(x_prof_cent, prof_vals, yerr=prof_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posteriors for the measured values\n",
    "\n",
    "Now we make \"Posterior\" objects\n",
    "\n",
    "`post_p` = $p(z|d_{j})$ \n",
    "\n",
    "`est_p` = $p(z | d_{j}, \\phi^{*})$ \n",
    "\n",
    "`true_p` = $p(z | d_{j}, \\phi^{\\dagger})$ \n",
    "\n",
    "for the samples we simulated.   Note that this is different than we made the grids above.   Now the index $j$ runs over the samples, i.e., for 10000 sampled galaxies we have 10000 entries in each of `post_p`, `est_p` and `true_p`, corresponding to the posterior PDFs for each of the sampled data values $d_j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we get the redshift posteriors for all the measured data\n",
    "z_meas_bin = np.searchsorted(grid_edge, z_meas_sample)-1\n",
    "z_meas_mask = (z_meas_bin >= 0) * (z_meas_bin < grid_cent.size)\n",
    "z_meas_bin = z_meas_bin[z_meas_mask]\n",
    "\n",
    "post_p = like_estim.make_posterior(z_grid, z_true_sample)\n",
    "est_p = like_estim.make_posterior(z_grid, z_true_sample, implicit_prior)\n",
    "true_p = like_estim.make_posterior(z_grid, z_true_sample, true_dist)\n",
    "\n",
    "def make_dict(post, z_grid):\n",
    "    ens = post._ensemble\n",
    "    vals = ens.pdf(z_grid)\n",
    "    return dict(post=post, ens=ens, vals=vals, stack=vals.mean(axis=0))\n",
    "\n",
    "post_dict = make_dict(post_p, z_grid)\n",
    "est_dict = make_dict(est_p, z_grid)\n",
    "true_dict = make_dict(true_p, z_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot a particular event from the sample, \n",
    "# so this one galaxy's posterior under the physical model of redshift and photometry, \n",
    "# under an estimation model with implicit prior $\\phi^{*}$,\n",
    "# and under a (very lucky) estimation model with implicit prior $\\phi^{\\dagger}$\n",
    "which_sample = np.argmax(z_meas_sample[0:100])\n",
    "fig_x, ax_x = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                           xlabel=r\"$z_{\\rm true}$\",\n",
    "                                           ylabel=r\"$p(z)$\")\n",
    "ax_x.plot(z_grid, post_dict['vals'][which_sample], label='posterior under flat implicit prior')\n",
    "ax_x.plot(z_grid, est_dict['vals'][which_sample], label='posterior under estimator\\'s implicit prior')\n",
    "ax_x.plot(z_grid, true_dict['vals'][which_sample], label='posterior under true redshift distribution as implict prior')\n",
    "ax_x.plot(z_grid, np.squeeze(implicit_prior.pdf(z_grid)), label=r'implicit prior = estimator\\'s $n^{*}(z)$')\n",
    "ax_x.plot(z_grid, np.squeeze(true_dist.pdf(z_grid)), label=r'implicit prior = true $n^{\\dagger}(z)$')\n",
    "leg = fig_x.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check of effect of binning the samples\n",
    "\n",
    "This compares a histogram made from the original $d$ values to a histogram made by taking the closest grid point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_check, ax_check = qp.plotting.make_figure_axes(xlim=(Z_OBS_MIN, Z_OBS_MAX),\n",
    "                                                   xlabel=r\"$z_{\\rm true}$\",\n",
    "                                                   ylabel=\"Counts / %0.02f\" % ((Z_OBS_MAX-Z_OBS_MIN)/N_OBS_HIST_BINS))\n",
    "\n",
    "ax_check.hist(z_meas_sample, bins=np.linspace(Z_OBS_MIN, Z_OBS_MAX, N_OBS_HIST_BINS+1), label='sample', histtype='step')\n",
    "z_meas_binned = grid_cent[z_meas_bin]\n",
    "ax_check.hist(z_meas_binned, bins=np.linspace(Z_OBS_MIN, Z_OBS_MAX, N_OBS_HIST_BINS+1), label='check', histtype='step')\n",
    "leg = fig_check.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the true redshift distribution to the naive \"stacking\"\n",
    "\n",
    "**Note: check interpretation that either implicit prior tightens distribution relative to physical model, and that the shift in mean is due to differences between using estimated vs. true n(z) as implicit prior.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N_FIT_BINS = 4\n",
    "hist_bins = np.linspace(Z_TRUE_MIN, Z_TRUE_MAX, N_FIT_BINS+1)\n",
    "fig_stack, ax_stack = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                                   xlabel=r\"$z_{\\rm true}$\",\n",
    "                                                   ylabel=r\"$p(z)$\")\n",
    "ax_stack.hist(z_true_sample[mask], bins=hist_bins, density=True, label=r'$z_{\\rm true}$', histtype='step')\n",
    "ax_stack.plot(z_grid, np.squeeze(true_dist.pdf(z_grid)), label=r'$p(z) = n^{\\dagger}(z)$')\n",
    "ax_stack.plot(z_grid, post_dict['stack'], label=r'$\\sum_{j} p(z | d_{j})$')\n",
    "ax_stack.plot(z_grid, est_dict['stack'], label=r'$\\sum_{j} p(z | d_{j}, \\phi^{\\dagger})$')\n",
    "ax_stack.plot(z_grid, true_dict['stack'], label=r'$\\sum_{j} p(z | d_{j}, \\phi^{*})$')\n",
    "leg = fig_stack.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some per-galaxy redshift posterior distributions\n",
    "\n",
    "**Note: check interpretation that implicit prior tightens distribution relative to physical model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1, ax_1 = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                                   xlabel=r\"$z_{\\rm true}$\",\n",
    "                                                   ylabel=r\"$p(z | d)$\")\n",
    "fig_2, ax_2 = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                                   xlabel=r\"$z_{\\rm true}$\",\n",
    "                                                   ylabel=r\"$p(z | d, \\phi^{*})$\")\n",
    "\n",
    "post_vals = post_dict['vals']\n",
    "est_vals = est_dict['vals']\n",
    "for i in range(10):\n",
    "    ax_1.plot(z_grid, post_vals[i])\n",
    "    ax_2.plot(z_grid, est_vals[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test to make sure we can update the parameters of a PDF for fitting\n",
    "\n",
    "This is just a software test to make sure that setting the values of a model parameter changes the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_params = np.ones((1, N_FIT_BINS))\n",
    "model = qp.Ensemble(qp.stats.hist, data=dict(bins=hist_bins, pdfs=model_params))\n",
    "fig_model, ax_model = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                                   xlabel=r\"$z_{\\rm true}$\",\n",
    "                                                   ylabel=r\"$p(z)$\")\n",
    "\n",
    "ax_model.plot(z_grid, np.squeeze(model.pdf(z_grid)), label='orig')\n",
    "\n",
    "new_params = np.ones(N_FIT_BINS)\n",
    "new_params[1] = 1.4\n",
    "\n",
    "model.update_objdata(dict(pdfs=np.expand_dims(new_params, 0)))\n",
    "ax_model.plot(z_grid, np.squeeze(model.pdf(z_grid)), label='new')\n",
    "leg = fig_model.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the likelihood function by evaluating it for a flat distribution and for the true redshift distribution\n",
    "\n",
    "Here \"model\" is our model of the implicit prior\n",
    "\n",
    "model = $p(z|\\alpha)$ , where $\\alpha$ are the hyper-parameters for our prior\n",
    "\n",
    "And \"llike\" is the likelihood associated to that model, computed by summing over the sample\n",
    "\n",
    "llike = $\\sum_i \\ln \\int P(z_{\\rm true}|d_i) \\frac{p(z|\\alpha)}{p(z|\\phi)}  dz_{\\rm true}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EVAL_PTS = 201\n",
    "eval_grid = np.linspace(Z_TRUE_MIN, Z_TRUE_MAX, N_EVAL_PTS)\n",
    "model_params = np.log(np.ones(N_FIT_BINS))\n",
    "hist_cents = qp.utils.edge_to_center(hist_bins)\n",
    "true_vals = np.histogram(z_true_sample, bins=np.linspace(Z_TRUE_MIN, Z_TRUE_MAX, N_FIT_BINS+1))[0]\n",
    "llike = qit.Likelihood(model, est_dict['post'], eval_grid)\n",
    "v_flat = llike(model_params)\n",
    "v_true = llike(np.log(true_vals))\n",
    "print(v_flat, v_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit for the hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(llike, model_params)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the current value of the objective function\n",
    "llike(result['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the parameters and convert back to counts (The Jacobian happens to be identical to the fitted values)\n",
    "fitted_vals = np.exp(result['x'])\n",
    "fitted_errs = np.sqrt(np.array([result['hess_inv'][i,i] for i in range(4)]))\n",
    "norm_factor = 2 / fitted_vals.sum()\n",
    "normed_fit = norm_factor * fitted_vals\n",
    "#jac = fitted_vals\n",
    "# Convert to PDF, for plotting\n",
    "#normed_errs = norm_factor * jac * fitted_errs\n",
    "model.update_objdata(dict(pdfs=np.expand_dims(normed_fit, 0)))\n",
    "model_vals = np.squeeze(model.pdf(z_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_result, ax_result = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                                     xlabel=r\"$z_{\\rm true}$\",\n",
    "                                                     ylabel=r\"$p(z)$\")\n",
    "ax_result.hist(z_true_sample[mask], bins=hist_bins, density=True, label=r'$z_{\\rm true}$', histtype='step')\n",
    "ax_result.plot(z_grid, np.squeeze(true_dist.pdf(z_grid)), label=r'$p(z)$')\n",
    "ax_result.plot(z_grid, post_dict['stack'], label=r'$\\sum_j p(z | d_{j}$)')\n",
    "ax_result.plot(z_grid, est_dict['stack'], label=r'$\\sum_j p(z | d_{j}, \\phi^{*})$')\n",
    "ax_result.plot(z_grid, true_dict['stack'], label=r'$\\sum_j p(z | d_{j}, \\phi^{\\dagger})$')\n",
    "#ax_result.errorbar(hist_cents, normed_fit, yerr=normed_errs, label=\"result\")\n",
    "ax_result.plot(z_grid, model_vals, label='model')\n",
    "leg = fig_result.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting in counts space\n",
    "\n",
    "Here we bin the data space and do the fit by computing the Poisson likelihood for the number of counts in each data bin.  \n",
    "\n",
    "$\\ln \\mathcal{L} = \\sum_j m_j - \\sum_j d_j \\log m_j$ \n",
    "\n",
    "where\n",
    "\n",
    "$d_j$ is the number of data counts in bin $j$\n",
    "\n",
    "$m_j$ is the number of model counts in bin $j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LIKE_PTS = 301\n",
    "like_grid = np.linspace(Z_OBS_MIN, Z_OBS_MAX, N_LIKE_PTS)\n",
    "#eval_bins = np.searchsorted(z_bins, eval_grid, side='left')-1\n",
    "#eval_mask = (eval_bins >= 0) * (eval_bins < z_bins.size-1)\n",
    "#eval_grid = eval_grid[eval_mask]\n",
    "#eval_bins = eval_bins[eval_mask]\n",
    "#like_eval = likelihood.pdf(like_grid)[eval_bins]\n",
    "obs_cts_grid = np.linspace(Z_OBS_MIN, Z_OBS_MAX, 7)\n",
    "data_hist = np.histogram(z_meas_sample, bins=obs_cts_grid)\n",
    "data_cts = data_hist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like = qit.BinnedLike(model=model, data_hist=data_hist, estimator=like_estim,\\\n",
    "                      like_grid=like_grid, model_grid=eval_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = 0.5*data_cts.sum()*np.ones(4)\n",
    "model_flat = like.model_counts(np.log(flat))\n",
    "model_true = like.model_counts(np.log(true_vals))\n",
    "ll_flat = like(np.log(flat))\n",
    "ll_true = like(np.log(true_vals))\n",
    "print(ll_flat, ll_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(like, np.ones(4))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cts = like.model_counts(result['x'])\n",
    "cts_cent = 0.5 * (obs_cts_grid[1:] + obs_cts_grid[:-1])\n",
    "fig_fit, ax_fit = qp.plotting.make_figure_axes(xlim=(Z_OBS_MIN, Z_OBS_MAX),\n",
    "                                                     xlabel=r\"$d$\",\n",
    "                                                     ylabel=r\"$n(d)$\")\n",
    "ax_fit.set_yscale('log')\n",
    "ax_fit.set_ylim(1., 1e4)\n",
    "ax_fit.scatter(cts_cent, data_cts, label='data')\n",
    "ax_fit.plot(cts_cent, model_cts, label='fit')\n",
    "leg = fig_fit.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_cts = np.exp(result['x'])\n",
    "fit_cts *= 2/fit_cts.sum()\n",
    "pdf_true = true_vals * 2 / true_vals.sum()\n",
    "fig_fit2, ax_fit2 = qp.plotting.make_figure_axes(xlim=(Z_TRUE_MIN, Z_TRUE_MAX),\n",
    "                                                xlabel=r'$z_{\\rm true}$',\n",
    "                                                ylabel=r'p(z)')\n",
    "\n",
    "ax_fit2.hist(z_true_sample[mask], bins=hist_bins, density=True, label=r'$z_{\\rm true}$', histtype='step')\n",
    "ax_fit2.plot(z_grid, np.squeeze(true_dist.pdf(z_grid)), label=r'$p(z)$')\n",
    "ax_fit2.plot(hist_cents, fit_cts, label=\"fit\")\n",
    "ax_fit2.plot(z_grid, model_vals, label='model')\n",
    "leg = fig_fit2.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DESC (Python 3)",
   "language": "python",
   "name": "desc_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
